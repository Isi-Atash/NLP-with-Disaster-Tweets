{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:58:08.818956700Z",
     "start_time": "2023-06-12T18:58:08.814897900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "plt.style.use('ggplot')\n",
    "stop=set(stopwords.words('english'))\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_tweet= pd.read_csv('data/train.csv')\n",
    "test_tweet=pd.read_csv('data/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:08:34.608681100Z",
     "start_time": "2023-06-12T18:08:34.594666700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_train = train_tweet.copy()\n",
    "df_test = test_tweet.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:08:50.038976200Z",
     "start_time": "2023-06-12T18:08:50.033764400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#remove HTML\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:09:37.521844500Z",
     "start_time": "2023-06-12T18:09:37.513880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#remove http\n",
    "def remove_http(text):\n",
    "    http=re.compile(r'http\\S+')\n",
    "    return http.sub(r'',text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:09:39.072112700Z",
     "start_time": "2023-06-12T18:09:39.066908500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#remove URL\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:09:40.767756600Z",
     "start_time": "2023-06-12T18:09:40.764228300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:09:42.335671300Z",
     "start_time": "2023-06-12T18:09:42.325310500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#tokenize\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:09:43.837750900Z",
     "start_time": "2023-06-12T18:09:43.833642100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#method to put all of the above together\n",
    "def clean_text(text):\n",
    "    text=remove_html(text)\n",
    "    text=remove_http(text)\n",
    "    text=remove_URL(text)\n",
    "    text=remove_punct(text)\n",
    "    text=tokenize(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:09:46.635933300Z",
     "start_time": "2023-06-12T18:09:46.633226200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def delete_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:10:05.135948500Z",
     "start_time": "2023-06-12T18:10:05.020136800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#delete stopwords\n",
    "df_train['text']=df_train['text'].apply(lambda x : delete_stopwords(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:10:09.253500300Z",
     "start_time": "2023-06-12T18:10:07.990203700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#apply clean_text method to df\n",
    "df_train['text']=df_train['text'].apply(lambda x : clean_text(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:10:50.955667500Z",
     "start_time": "2023-06-12T18:10:50.439182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text  \\\n0   1     NaN      NaN  [Deeds, Reason, earthquake, May, ALLAH, Forgiv...   \n1   4     NaN      NaN      [Forest, fire, near, La, Ronge, Sask, Canada]   \n2   5     NaN      NaN  [residents, asked, shelter, place, notified, o...   \n3   6     NaN      NaN  [13000, people, receive, wildfires, evacuation...   \n4   7     NaN      NaN  [got, sent, photo, Ruby, Alaska, smoke, wildfi...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Deeds, Reason, earthquake, May, ALLAH, Forgiv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Forest, fire, near, La, Ronge, Sask, Canada]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[residents, asked, shelter, place, notified, o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[13000, people, receive, wildfires, evacuation...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[got, sent, photo, Ruby, Alaska, smoke, wildfi...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:10:59.243540800Z",
     "start_time": "2023-06-12T18:10:59.236205200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#tokenize\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(df_train['text'])\n",
    "word_index_dict=tokenizer_obj.word_index\n",
    "#num of unique words\n",
    "num_words=len(word_index_dict)+1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:11:48.565857900Z",
     "start_time": "2023-06-12T18:11:48.523208800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18076\n"
     ]
    }
   ],
   "source": [
    "print(num_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:11:50.025711500Z",
     "start_time": "2023-06-12T18:11:50.020156200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#use GloVe for word embedding\n",
    "#dictionary with the words as keys and the embeddings as values\n",
    "def glove_embedding(df):\n",
    "    embeddings_index = {}\n",
    "    f = open('glove/glove.6B.100d.txt',encoding='utf8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:])\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:12:06.365287500Z",
     "start_time": "2023-06-12T18:12:06.360321200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = glove_embedding(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:12:53.587355100Z",
     "start_time": "2023-06-12T18:12:45.520114700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#create a method to create a matrix with the embeddings\n",
    "def create_embedding_matrix(df):\n",
    "    embedding_matrix=np.zeros((num_words,100))\n",
    "    for word,i in word_index_dict.items():\n",
    "        if i > num_words:\n",
    "            continue\n",
    "        emb_vec=embeddings_dict.get(word)\n",
    "        if emb_vec is not None:\n",
    "            embedding_matrix[i]=emb_vec\n",
    "    return embedding_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:12:55.379884800Z",
     "start_time": "2023-06-12T18:12:55.376239900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "embedding_matrix=create_embedding_matrix(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:13:08.845724400Z",
     "start_time": "2023-06-12T18:13:08.366925300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def create_cnn_model(embedding_matrix, input_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
    "                        weights=[embedding_matrix], input_length=input_length, trainable=False))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_cnn_model(embedding_matrix, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:34:55.255921200Z",
     "start_time": "2023-06-12T18:34:55.204502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# def create_model(embedding_matrix, input_length):\n",
    "#     model =tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Embedding(num_words,100,embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "#                                   input_length=50,trainable=False),\n",
    "#         tf.keras.layers.Conv1D(128,7,activation='relu'),\n",
    "#         tf.keras.layers.Conv1D(256, 7, activation='relu'),\n",
    "#         tf.keras.layers.Conv1D(128, 7, activation='relu'),\n",
    "#         # LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "#         tf.keras.layers.GlobalMaxPooling1D(),\n",
    "#         tf.keras.layers.Dense(64,activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "#     ])\n",
    "#\n",
    "#     model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     return model\n",
    "#\n",
    "# model = create_model(embedding_matrix, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:31:11.105703900Z",
     "start_time": "2023-06-12T18:31:11.059277900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 50, 100)           1807600   \n",
      "                                                                 \n",
      " conv1d_30 (Conv1D)          (None, 46, 128)           64128     \n",
      "                                                                 \n",
      " global_max_pooling1d_14 (Gl  (None, 128)              0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,880,049\n",
      "Trainable params: 72,449\n",
      "Non-trainable params: 1,807,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T18:34:58.572118800Z",
     "start_time": "2023-06-12T18:34:58.561188600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "sequences = tokenizer_obj.texts_to_sequences(df_train['text'])\n",
    "MAX_LEN = 50\n",
    "tweet_pad = pad_sequences(sequences, maxlen=MAX_LEN, truncating='post', padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:19:48.896544100Z",
     "start_time": "2023-06-12T19:19:48.852955700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "train=tweet_pad[:df_train.shape[0]]\n",
    "test=tweet_pad[:df_train.shape[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:18:34.981489Z",
     "start_time": "2023-06-12T19:18:34.981489Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "#split data into train and test\n",
    "X_train,X_test,y_train,y_test=train_test_split(train,df_train['target'].values,test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:37:14.906590300Z",
     "start_time": "2023-06-12T19:37:14.892830500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1523/1523 - 3s - loss: 0.0569 - accuracy: 0.9785 - val_loss: 0.0366 - val_accuracy: 0.9842 - 3s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "1523/1523 - 3s - loss: 0.0387 - accuracy: 0.9806 - val_loss: 0.0383 - val_accuracy: 0.9810 - 3s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "1523/1523 - 3s - loss: 0.0377 - accuracy: 0.9811 - val_loss: 0.0427 - val_accuracy: 0.9823 - 3s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "1523/1523 - 3s - loss: 0.0426 - accuracy: 0.9796 - val_loss: 0.0499 - val_accuracy: 0.9803 - 3s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "1523/1523 - 3s - loss: 0.0415 - accuracy: 0.9798 - val_loss: 0.0676 - val_accuracy: 0.9816 - 3s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "1523/1523 - 3s - loss: 0.0370 - accuracy: 0.9821 - val_loss: 0.0534 - val_accuracy: 0.9829 - 3s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "1523/1523 - 3s - loss: 0.0433 - accuracy: 0.9803 - val_loss: 0.0624 - val_accuracy: 0.9796 - 3s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "1523/1523 - 3s - loss: 0.0449 - accuracy: 0.9801 - val_loss: 0.0788 - val_accuracy: 0.9790 - 3s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "1523/1523 - 3s - loss: 0.0315 - accuracy: 0.9831 - val_loss: 0.0828 - val_accuracy: 0.9750 - 3s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "1523/1523 - 3s - loss: 0.0365 - accuracy: 0.9819 - val_loss: 0.0841 - val_accuracy: 0.9764 - 3s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "history=model.fit(X_train,y_train,batch_size=4,epochs=10,validation_data=(X_test,y_test),verbose=2)\n",
    "# model.fit(X_train,y_train,batch_size=4,epochs=10,validation_data=(X_test,y_test),verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:38:07.709583400Z",
     "start_time": "2023-06-12T19:37:38.739548200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [
    {
     "data": {
      "text/plain": "3263"
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_test\n",
    "df_test.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:39:00.243922900Z",
     "start_time": "2023-06-12T19:39:00.230357900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "sequences = tokenizer_obj.texts_to_sequences(df_test['text'])\n",
    "MAX_LEN = 50\n",
    "tweet_pad = pad_sequences(sequences, maxlen=MAX_LEN, truncating='post', padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:40:39.573551800Z",
     "start_time": "2023-06-12T19:40:39.532230900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2909   772   240 ...     0     0     0]\n",
      " [  348 13456   154 ...     0     0     0]\n",
      " [  974  1032   240 ...     0     0     0]\n",
      " ...\n",
      " [  831   600   243 ...     0     0     0]\n",
      " [ 6129   472   364 ...     0     0     0]\n",
      " [ 5811  6357  2648 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "test=tweet_pad[:df_test.shape[0]]\n",
    "print(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:40:41.135816400Z",
     "start_time": "2023-06-12T19:40:41.127580900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "sample_submission[\"target\"] = model.predict(test)\n",
    "sample_submission[\"target\"] = sample_submission[\"target\"].apply(lambda x: 1 if x > 0.3 else 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:44:14.743880900Z",
     "start_time": "2023-06-12T19:44:14.512970100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [
    {
     "data": {
      "text/plain": "target\n0    2356\n1     907\nName: count, dtype: int64"
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_submission.head()\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)\n",
    "sample_submission['target'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:44:21.600592800Z",
     "start_time": "2023-06-12T19:44:21.591910900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "outputs": [
    {
     "data": {
      "text/plain": "correct\nTrue     2597\nFalse     666\nName: count, dtype: int64"
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = pd.read_csv(\"data/ms.csv\")\n",
    "submission = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "# Compare target columns\n",
    "comparison = ms['target'] == submission['target']\n",
    "\n",
    "# Create a new DataFrame with the comparison results\n",
    "comparison_df = pd.DataFrame({'ms_target': ms['target'], 'submission_target': submission['target'], 'correct': comparison})\n",
    "\n",
    "# Display the comparison DataFrame\n",
    "# print(comparison_df)\n",
    "comparison_df['correct'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T19:44:17.143797300Z",
     "start_time": "2023-06-12T19:44:17.130799100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 0.3\n",
    "True,2597\n",
    "False,666\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
